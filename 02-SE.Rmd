---
title: "DADA2 tutorial - PE reads"
output:
  rmarkdown::html_document:
    toc: true
    toc_float: true
params:
  process: FALSE
---

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy()
```

<br>

----

## Organize folders and files

First we need to create a folder named `project` with this structure:

```
project
  |___data
```

Now, we can move and move all our `.fastq.gz` to the folder named `data`, create a `.txt` file with the metadata and a empty `R` file where we will store our code. The project folder will look like this:

```
project
|___data
|     | file1.fastq.gz
|     | file2.fastq.gz
|     | ....... .fastq.gz
|
|___metadata.txt
|___rcode.R
```

<br>

### Download the data

Normally, you would just copy the data from your long-term storage device to the folder `project/data`. In this case we will download the data from GitHub. 

[Download this file](https://downgit.github.io/#/home?url=https://github.com/amalacrino/files_tutorials/tree/main/WWU_tutorial_2/data) and unzip it inside the folder `project/data`.

<br>

### Create the metadata file

Within the project folder, you need to save a file named `metadata.txt` (tab-separated values). The structure of this file should look like this:

```
SampleID    Factor1       Factor2   ...   FactorN
S1          Control       Root      ...
S2          Treatment     Root      ...
```

For this tutorial, you can download one from [here](https://raw.githubusercontent.com/amalacrino/files_tutorials/main/WWU_tutorial_2/metadata.txt) and place it inside the `project/` folder. 

<br>

### Step 3. Create a R file

The quickest way to do so is to:

  - Open R Studio
  - Click on `File/New File/ R Script`
  - Click on `File/Save`
  - Navigate to your project folder and save it
  - Close R Studio
  - Open the file you just saved. In this way R Studio will open the file with that relative path already set, so you do not have to worry about changing your code every time you move the folder or when starting a new project.
  
<br>

### Load packages

```{r, eval=params$process, warning=FALSE, message=FALSE}
library("tidyverse")
library("gridExtra")
library("dada2")
library("phyloseq")
library("DECIPHER")
library("phangorn")
library("ape")
library("seqinr")
```

<br>

### File preparation

First, we specify the number of threads to use when multithreaded functions are available.

```{r, eval=params$process}
n_cores <- 8
```

Then we run a list of commands to create some folders and specify paths to keep files organized.

```{r, eval=params$process}
indir <- "data"
filter_dir <- 'fastq_filtered'
outdir <- 'ASVs'
tax <- 'SILVA'
tax_key <- 'SILVA/silva_nr99_v138.1_wSpecies_train_set.fa.gz'
metadata_file <- 'metadata.txt'
tree <- 'tree.tre'
asv.final.table <- 'ASV_table.rds'

dir.create(filter_dir, showWarnings = FALSE, recursive = TRUE)
dir.create(tax, showWarnings = FALSE, recursive = TRUE)
dir.create(outdir, showWarnings = FALSE, recursive = TRUE)
```

And then we can download the SILVA database (v138) that we will use for taxonomic assignment.

```{r, eval=params$process}
download.file("https://zenodo.org/record/4587955/files/silva_nr99_v138.1_wSpecies_train_set.fa.gz", file.path(tax, 'silva_nr99_v138.1_wSpecies_train_set.fa.gz'))
```

And, finally, load the metadata

```{r, eval=params$process}
metadata_df <- read.table(file = metadata_file, sep = "\t", header = TRUE, row.names = 1)
```

<br>

### Run the DADA2 workflow

List `.fastq.gz` files, assuming filenames have format: `SAMPLENAME.fastq`.

```{r, eval=params$process}
fastqs_raw <- sort(list.files(indir, pattern = '.fastq', full.names = TRUE))
sampleIDs <- sub("*.fastq", "", basename(fastqs_raw))
```

Inspect the read quality profiles.

```{r, eval=params$process}
plotQualityProfile(fastqs_raw[1])
```

Then we can define the file path for filtered files and define filenames.

```{r, eval=params$process}
fastqs_filt <- file.path(filter_dir, paste0(sampleIDs, '.filt.fastq'))
names(fastqs_filt) <- sampleIDs
```

Filter and trim raw reads.

```{r, eval=params$process}
filter_results <- filterAndTrim(fastqs_raw, fastqs_filt,
                                truncLen = 250,
                                rm.phix = FALSE,
                                multithread = n_cores, 
                                compress = FALSE, verbose = TRUE) 
```

<details>
<summary>
&nbsp; `r icons::fontawesome("info-circle")` &nbsp; **What can be changed?** (Click here)
</summary>

`compress = TRUE` (Optional). Default TRUE. If TRUE, the output fastq file(s) are gzipped. 

`truncQ = 2` (Optional). Default 2. Truncate reads at the first instance of a quality score less than or equal to `truncQ`.

`truncLen = 0` (Optional). Default 0 (no truncation). Truncate reads after `truncLen` bases. Reads shorter than this are discarded.

`trimLeft = 0` (Optional). Default 0. The number of nucleotides to remove from the start of each read. If both `truncLen` and `trimLeft` are provided, filtered reads will have length `truncLen`-`trimLeft`.

`trimRight = 0` (Optional). Default 0. The number of nucleotides to remove from the end of each read. If both `truncLen` and `trimRight` are provided, truncation will be performed after `trimRight` is enforced.

`maxLen = Inf` (Optional). Default Inf (no maximum). Remove reads with length greater than `maxLen.` `maxLen` is enforced before trimming and truncation.

`minLen = 20` (Optional). Default 20. Remove reads with length less than `minLen.` `minLen` is enforced after trimming and truncation.

`maxN = 0` (Optional). Default 0. After truncation, sequences with more than maxN Ns will be discarded. Note that dada does not allow Ns.

`minQ = 0` (Optional). Default 0. After truncation, reads contain a quality score less than minQ will be discarded.

`maxEE = Inf` (Optional). Default `Inf` (no EE filtering). After truncation, reads with higher than maxEE "expected errors" will be discarded. Expected errors are calculated from the nominal definition of the quality score: EE = sum(10^(-Q/10))

`rm.phix = TRUE` (Optional). Default TRUE. If TRUE, discard reads that match against the phiX genome, as determined by `isPhiX`.

</details>

<br>

Check how many reads have been filtered.

```{r, eval=params$process}
filter_results
```

Remove those samples that have been completely filtered out.

```{r, eval=params$process}
exists <- file.exists(fastqs_raw) & file.exists(fastqs_filt)
fastqs_filt <- fastqs_filt[exists]
```

Learn error rates.

```{r, eval=params$process}
err <- learnErrors(fastqs_filt, multithread = n_cores, verbose = TRUE)
```

Run sample inference.

```{r, eval=params$process}
dada_asvs <- dada(fastqs_filt, err = err, pool = FALSE, multithread = n_cores)
```

<details>
<summary>
&nbsp; `r icons::fontawesome("info-circle")` &nbsp; **What can be changed?** (Click here)
</summary>

`pool` (Optional). If `pool = TRUE`, the algorithm will pool together all samples prior to sample inference. If `pool = FALSE`, sample inference is performed on each sample individually. If `pool = "pseudo"`, the algorithm will perform pseudo-pooling between individually processed samples. 

`priors` (Optional). The priors argument provides a set of sequences for which there is prior information suggesting they may truly exist, i.e. are not errors. The abundance p-value of dereplicated sequences that exactly match one of the priors are calculated without conditioning on presence, allowing singletons to be detected, and are compared to a reduced threshold 'OMEGA_P' when forming new partitions.

</details>

<br>


Construct ASV table.

```{r, eval=params$process}
seqtab_all <- makeSequenceTable(dada_asvs)
```

<details>
<summary>
&nbsp; `r icons::fontawesome("info-circle")` &nbsp; **What can be changed?** (Click here)
</summary>

`orderBy` (Optional). `character(1)`. Default "abundance". Specifies how the sequences (columns) of the returned table should be ordered (decreasing). Valid values: "abundance", "nsamples", NULL.

</details>

<br>

Remove chimeras.

```{r, eval=params$process}
seqtab <- removeBimeraDenovo(seqtab_all,
                             method = 'consensus',
                             multithread = n_cores,
                             verbose = TRUE)
```

<details>
<summary>
&nbsp; `r icons::fontawesome("info-circle")` &nbsp; **What can be changed?** (Click here)
</summary>

`method` (Optional). Default is "consensus". Only has an effect if a sequence table is provided. If `pooled`: The samples in the sequence table are all pooled together for bimera identification (`isBimeraDenovo`). If `consensus`: The samples in a sequence table are independently checked for bimeras, and a consensus decision on each sequence variant is made (`isBimeraDenovoTable`). If `per-sample`: The samples in a sequence table are independently checked for bimeras, and sequence variants are removed (zeroed-out) from samples independently (`isBimeraDenovo`).

</details>

<br>

Track reads through the pipeline.

```{r, eval=params$process}
getN <- function(x) sum(getUniques(x))
track <- cbind(filter_results, sapply(dada_asvs, getN), rowSums(seqtab))
colnames(track) <- c("input", "filtered", "denoised", "nonchim")
rownames(track) <- sampleIDs
track
```

Assign taxonomy.

```{r, eval=params$process}
taxa <- assignTaxonomy(seqtab, tax_key, multithread = n_cores)
colnames(taxa) <- c('Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', "Species")
```

Rename ASVs (optional).

```{r, eval=params$process}
otutable <- seqtab
colnames(otutable) <- paste('ASV', 1:ncol(seqtab), sep = '_')
row.names(taxa) <- paste('ASV', 1:ncol(seqtab), sep = '_')
```

Generate `.fasta` file with ASVs.

```{r, eval=params$process}
asv_seqs <- colnames(seqtab)
asv_headers <- paste('ASV', 1:ncol(seqtab), sep = '_')
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, file = file.path(outdir, 'ASVs.fa')) #optional
```

Align sequences.

```{r, eval=params$process}
seqs <- getSequences(seqtab)
names(seqs) <- asv_headers 
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA, processors = n_cores)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
write.phyDat(phang.align, file = file.path(outdir, 'alignment.fasta'), format="fasta") #optional
```

Build phylogenetic tree with ASVs.

```{r, eval=params$process}
dna_dist <- dist.ml(phang.align, model="JC69")
asv_UPGMA <- upgma(dna_dist)
fit <- pml(asv_UPGMA, phang.align)
fitJC <- optim.pml(fit, model = "JC", rearrangement = "stochastic")
tree <- bootstrap.pml(fitJC, bs=1, optNni=TRUE, multicore=TRUE, control = pml.control(trace=0))
```

<br>

### Generate phyloseq object

```{r, eval=params$process}
ps <- phyloseq(otu_table(otutable, taxa_are_rows = FALSE),
                   sample_data(metadata_df),
                   tax_table(taxa),
                   tree[[1]])
ps
```

Clean environment and save it.

```{r, eval=params$process}
rm(list=setdiff(ls(), c("ps")))
save.image(file = asv.final.table)
```

```{r, eval=params$process}
sessionInfo()
```